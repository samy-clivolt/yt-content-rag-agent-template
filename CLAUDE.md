# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a Mastra-based application that provides weather information and activity planning through an AI agent system. The project uses TypeScript, Node.js (>=20.9.0), and the Mastra framework for building AI agents and workflows.

## Key Commands

- `npm run dev` - Start the Mastra development server
- `npm run build` - Build the Mastra application
- `npm start` - Start the Mastra application in production mode
- `npm test` - Currently not configured (exits with error)

## Architecture

### Core Technologies
- **Mastra Framework**: For AI agents, workflows, and tool creation
- **OpenAI GPT-4**: As the LLM model for the weather agent
- **LibSQL**: For telemetry and memory storage
- **Zod**: For schema validation
- **TypeScript**: With ES2022 modules and strict mode enabled

### Project Structure

The application follows a modular architecture:

1. **Main Configuration** (`src/mastra/index.ts`): Initializes the Mastra instance with workflows, agents, storage, and logging configuration. Currently uses in-memory storage but can be configured to persist to disk.

2. **Weather Agent** (`src/mastra/agents/weather-agent.ts`): An AI agent that provides weather information and activity suggestions. It uses GPT-4o-mini model and has access to the weather tool. The agent maintains conversation memory using LibSQL storage.

3. **Weather Tool** (`src/mastra/tools/weather-tool.ts`): A Mastra tool that fetches real-time weather data using:
   - Open-Meteo Geocoding API for location lookup
   - Open-Meteo Weather API for current conditions
   - Returns temperature, humidity, wind data, and weather conditions

4. **Weather Workflow** (`src/mastra/workflows/weather-workflow.ts`): A two-step workflow that:
   - Fetches weather forecast data for a city
   - Plans activities based on weather conditions using the weather agent
   - Streams responses directly to stdout

### Key Design Patterns

- **Tool Creation**: Uses `createTool` from Mastra with Zod schemas for input/output validation
- **Workflow Composition**: Uses `createWorkflow` with chained steps via `.then()`
- **Agent Integration**: Workflows can access agents through the `mastra` context
- **Error Handling**: Explicit error handling for missing locations and data
- **Type Safety**: Full TypeScript support with strict mode and comprehensive interfaces

## YouTube Content RAG System

### Vue d'ensemble
Syst√®me de base de donn√©es vectorielle pour stocker et rechercher dans les transcriptions YouTube en utilisant les capacit√©s RAG de Mastra avec une architecture bas√©e sur des workflows.

### Architecture impl√©ment√©e

#### 1. Workflow d'extraction (`src/mastra/workflows/youtube-rag-workflow.ts`) ‚úÖ
Pipeline optimis√© en 6 √©tapes :
1. **R√©cup√®re les m√©tadonn√©es** : Utilise `youtubeMetadataTool` (YouTube API) pour titre, description, etc.
2. **R√©cup√®re la transcription** : Utilise `youtubeTranscriptTool` (Apify)
3. **G√©n√®re les keywords SEO** : Agent `seoKeywordAgent` avec structured output
4. **G√©n√®re les chapitres** : Agent `chapterGeneratorAgent` avec timestamps
5. **Enrichit les chapitres** : Extrait la transcription sp√©cifique de chaque chapitre
6. **Chunking intelligent** : Utilise `youtubeChapterChunkerTool` pour cr√©er un chunk par chapitre avec :
   - Extraction de keywords suppl√©mentaires via MDocument
   - G√©n√©ration de r√©sum√©s concis (150 caract√®res) par chapitre
   - Pr√©servation du contexte complet (1 chunk = 1 chapitre)

#### 2. Syst√®me RAG avec PgVector ‚úÖ

##### Configuration de la base de donn√©es
- **PostgreSQL** avec extension **pgvector** pour le stockage vectoriel
- **Sch√©ma d√©di√©** `yt_rag` pour isoler les donn√©es
- **Tables automatiques** cr√©√©es par PgVector lors de `createIndex()`
- **Index HNSW** pour des performances optimales de recherche

##### Architecture des workflows RAG (approche recommand√©e)
Au lieu d'utiliser un service, l'architecture privil√©gie des workflows composables :

1. **youtube-index-workflow** : Pipeline d'indexation
   - Step 1: Ex√©cuter `youtube-rag-workflow` pour extraire les chapitres
   - Step 2: G√©n√©rer les embeddings avec OpenAI
   - Step 3: Stocker dans PgVector avec m√©tadonn√©es enrichies

2. **youtube-search-workflow** : Pipeline de recherche
   - Step 1: G√©n√©rer l'embedding de la requ√™te
   - Step 2: Rechercher dans PgVector
   - Step 3: Reranker et formater les r√©sultats

3. **youtube-rag-agent** : Agent intelligent utilisant `vectorQueryTool`
   - Comprend le contexte des questions
   - Utilise le filtrage par m√©tadonn√©es
   - Peut reranker les r√©sultats avec GPT-4.1

#### 3. Structure de donn√©es enrichie ‚úÖ

##### Donn√©es extraites par chunk
```typescript
{
  id: string,            // ID unique bas√© sur le titre du chapitre
  timestamp: string,     // "00:00" format MM:SS
  title: string,         // Titre SEO-optimis√© du chapitre
  startTime: number,     // En secondes
  endTime: number,       // En secondes
  text: string,          // Transcription compl√®te du chapitre
  keywords: string[],    // Keywords SEO contextuels + extraits
  summary?: string,      // R√©sum√© concis du chapitre (150 caract√®res)
  metadata: {
    videoTitle: string,  // Titre de la vid√©o YouTube
    chapterTitle: string,
    isFullChapter: true, // Toujours true (1 chunk = 1 chapitre)
    totalChunksInChapter: 1,
    originalChapterLength: number
  }
}
```

##### M√©tadonn√©es stock√©es avec chaque embedding
```typescript
{
  videoUrl: string,
  videoTitle: string,
  chapterTitle: string,
  chapterTimestamp: string,
  chapterStartTime: number,
  chapterEndTime: number,
  keywords: string[],
  indexedAt: Date
}
```

#### 4. Configuration et setup ‚úÖ

##### Pr√©requis
- PostgreSQL 12+ avec extension pgvector
- Variables d'environnement configur√©es

##### Installation de la base de donn√©es
```bash
# Script automatique
./scripts/setup-database.sh

# Ou manuellement
brew install pgvector  # macOS
psql -U postgres -d yt_rag -f scripts/setup-database.sql
```

##### Variables d'environnement requises
```env
# Base de donn√©es
POSTGRES_CONNECTION_STRING="postgresql://user:password@localhost:5432/yt_rag"

# APIs
OPENAI_API_KEY="sk-..."
APIFY_API_TOKEN="apify_api_..."
YOUTUBE_API_KEY="AIza..."
```

#### 5. Outils et composants ‚úÖ

- **youtubeMetadataTool** : R√©cup√®re titre, description et m√©tadonn√©es via YouTube API
- **youtubeTranscriptTool** : Extrait la transcription compl√®te via Apify
- **youtubeChapterChunkerTool** : Cr√©e des chunks intelligents avec extraction de metadata
- **youtubeVectorQueryTool** : Tool configur√© pour PgVector avec filtrage et optimisations
- **PgVector Store** : Configuration avec index HNSW (m=16, efConstruction=64)
- **Embedding Model** : OpenAI text-embedding-3-small (1536 dimensions)
- **Distance Metric** : Cosine similarity pour la recherche s√©mantique

### Utilisation

#### 1. Extraction et enrichissement des chapitres
```bash
# Test du workflow d'extraction
npx tsx src/test-rag-workflow-with-env.ts
```

#### 2. Indexation d'une vid√©o (√† impl√©menter)
```typescript
// Utilisation du youtube-index-workflow
const result = await mastra.workflows.youtubeIndexWorkflow.execute({
  input: { videoUrl: 'https://youtube.com/watch?v=...' }
});
```

#### 3. Recherche s√©mantique (√† impl√©menter)
```typescript
// Utilisation du youtube-search-workflow
const results = await mastra.workflows.youtubeSearchWorkflow.execute({
  input: { 
    query: 'comment fonctionne l\'IA',
    topK: 5
  }
});
```

#### 4. Utilisation de l'agent RAG
```typescript
// L'agent comprend le contexte et peut filtrer
const response = await youtubeRAGAgent.generate(
  "Trouve des informations sur le machine learning dans les vid√©os index√©es"
);
```

### Exemple de sortie du workflow d'extraction
```
‚úÖ Workflow completed successfully!

üîë SEO Keywords: Eric Schmidt, Google chairman, Steel Perlot, ...

üìö Chapters with Transcripts:
1. [00:00] Eric Schmidt's $20B Influence
   Duration: 16s
   Keywords: Eric Schmidt, startup accelerator
   Transcript preview: since leaving Google as chairman...
   ---
```

### Avantages de l'architecture workflow

1. **Modularit√©** : Chaque workflow est ind√©pendant et r√©utilisable
2. **Composabilit√©** : Les workflows peuvent s'appeler entre eux
3. **Observabilit√©** : Tra√ßage automatique avec la t√©l√©m√©trie Mastra
4. **Type Safety** : Validation avec Zod √† chaque √©tape
5. **Scalabilit√©** : Peut √™tre d√©ploy√© sur diff√©rentes infrastructures

### Architecture RAG optimis√©e

1. **Chunking intelligent** : Bas√© sur les chapitres g√©n√©r√©s par IA
2. **M√©tadonn√©es riches** : Keywords contextuels par chapitre
3. **Timestamps pr√©cis** : Conversion automatique MM:SS ‚Üî secondes
4. **Recherche hybride** : Combinaison de similarit√© vectorielle et filtrage
5. **Reranking optionnel** : Avec GPT-4.1 pour am√©liorer la pertinence

### √âtat actuel et prochaines √©tapes

#### ‚úÖ Impl√©ment√©
1. Workflow d'extraction complet avec 6 √©tapes
2. M√©tadonn√©es YouTube via API officielle
3. Chunking intelligent (1 chunk = 1 chapitre)
4. Extraction de keywords et r√©sum√©s par chapitre
5. Structure de donn√©es optimis√©e pour RAG

#### üîÑ Prochaine √©tape : G√©n√©ration des embeddings
La prochaine √©tape consistera √† :
1. Cr√©er un step pour g√©n√©rer les embeddings de chaque chunk
2. Utiliser OpenAI text-embedding-3-small (1536 dimensions)
3. Combiner le r√©sum√© + texte pour un embedding plus riche
4. Pr√©parer les donn√©es pour le stockage dans PgVector

### Notes importantes
- Toujours utiliser `gpt-4.1` pour les mod√®les OpenAI (pr√©f√©rence utilisateur)
- Le workflow d'extraction traite une vid√©o de 7 min en ~15 secondes
- PgVector cr√©e automatiquement les tables lors du premier `createIndex()`
- L'index HNSW offre le meilleur compromis performance/pr√©cision
- Process exit n√©cessaire pour terminer proprement (`process.exit(0)`)
- JAMAIS faire plus que ce que demande l'utilisateur.